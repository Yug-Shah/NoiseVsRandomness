{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60506fd9-2a1b-42a6-acc3-ee7ad34f2889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "06b77ea0-86c8-4578-8eee-2262c43164d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "#from pennylane.optimize import NesterovMomentumOptimizer\n",
    "\n",
    "#100 qubits required!!!!!!!!\n",
    "\n",
    "dev = qml.device(\"default.qubit\")\n",
    "def layer(layer_weights):\n",
    "    for wire in range(100):\n",
    "        qml.Rot(*layer_weights[wire], wires=wire)\n",
    "\n",
    "    for wires in range(99):\n",
    "        qml.CNOT([wires, wires+1])\n",
    "    qml.CNOT([99,0])\n",
    "\n",
    "def state_preparation(x):\n",
    "    qml.BasisState(x, wires=list(range(100)))\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(weights, x):\n",
    "    state_preparation(x)\n",
    "\n",
    "    for layer_weights in weights:\n",
    "        layer(layer_weights)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f2bfbe11-f2eb-45ad-9c1b-48472b4493c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(weights, bias, x):\n",
    "    return circuit(weights, x) + bias\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    # We use a call to qml.math.stack to allow subtracting the arrays directly\n",
    "    return np.mean((labels - qml.math.stack(predictions)) ** 2)\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "    acc = sum(abs(l - p) < 1e-5 for l, p in zip(labels, predictions))\n",
    "    acc = acc / len(labels)\n",
    "    return acc\n",
    "\n",
    "def cost(weights, bias, X, Y):\n",
    "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
    "    return square_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea904664-5d65-4b54-94e1-783859333b60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [0 1 1 0], y = -1\n",
      "x = [1 0 0 1], y = 1\n",
      "x = [1 1 0 1], y = 1\n",
      "x = [1 1 1 1], y = -1\n",
      "x = [0 0 0 0], y = 1\n",
      "x = [0 1 1 0], y = -1\n",
      "x = [1 0 0 1], y = 1\n",
      "x = [1 1 0 1], y = 1\n",
      "x = [1 1 1 1], y = -1\n",
      "x = [0 0 0 0], y = 1\n"
     ]
    }
   ],
   "source": [
    "# Convert binary strings to list of bits\n",
    "def binary_to_bits(binary_list):\n",
    "    return [[int(bit) for bit in binary_string] for binary_string in binary_list]\n",
    "# Suppose we have the following binary dataset\n",
    "X = np.array(binary_to_bits(['0110', '1001', '1101', '1111', '0000','0110', '1001', '1101', '1111', '0000']))\n",
    "Y = np.array([0, 1, 1, 0, 1,0, 1, 1, 0, 1]) \n",
    "Y = Y * 2 - 1  # shift label from {0, 1} to {-1, 1}\n",
    "\n",
    "for x,y in zip(X, Y):\n",
    "    print(f\"x = {x}, y = {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "897aa56a-37f4-42ae-bdbb-244cc82c3c03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [[[ 0.01764052  0.00400157  0.00978738]\n",
      "  [ 0.02240893  0.01867558 -0.00977278]\n",
      "  [ 0.00950088 -0.00151357 -0.00103219]\n",
      "  [ 0.00410599  0.00144044  0.01454274]]\n",
      "\n",
      " [[ 0.00761038  0.00121675  0.00443863]\n",
      "  [ 0.00333674  0.01494079 -0.00205158]\n",
      "  [ 0.00313068 -0.00854096 -0.0255299 ]\n",
      "  [ 0.00653619  0.00864436 -0.00742165]]]\n",
      "Bias:  0.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "num_qubits = 4\n",
    "num_layers = 2\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "print(\"Weights:\", weights_init)\n",
    "print(\"Bias: \", bias_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc9b2950-c25f-461d-ae8c-788f3a52882e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:    1 | Cost: 0.8080190 | Accuracy: 0.8000000\n",
      "Iter:    2 | Cost: 0.8016783 | Accuracy: 0.8000000\n",
      "Iter:    3 | Cost: 0.7966312 | Accuracy: 0.8000000\n",
      "Iter:    4 | Cost: 0.7902457 | Accuracy: 0.8000000\n",
      "Iter:    5 | Cost: 0.7832047 | Accuracy: 0.8000000\n",
      "Iter:    6 | Cost: 0.7771038 | Accuracy: 0.8000000\n",
      "Iter:    7 | Cost: 0.7702430 | Accuracy: 0.8000000\n",
      "Iter:    8 | Cost: 0.7627502 | Accuracy: 0.8000000\n",
      "Iter:    9 | Cost: 0.7547155 | Accuracy: 0.8000000\n",
      "Iter:   10 | Cost: 0.7462006 | Accuracy: 0.8000000\n",
      "Iter:   11 | Cost: 0.7372791 | Accuracy: 0.8000000\n",
      "Iter:   12 | Cost: 0.7280708 | Accuracy: 0.8000000\n",
      "Iter:   13 | Cost: 0.7186356 | Accuracy: 0.8000000\n",
      "Iter:   14 | Cost: 0.7089561 | Accuracy: 0.8000000\n",
      "Iter:   15 | Cost: 0.6990257 | Accuracy: 0.8000000\n",
      "Iter:   16 | Cost: 0.6891138 | Accuracy: 0.8000000\n",
      "Iter:   17 | Cost: 0.6791942 | Accuracy: 0.8000000\n",
      "Iter:   18 | Cost: 0.6692663 | Accuracy: 0.8000000\n",
      "Iter:   19 | Cost: 0.6603268 | Accuracy: 0.8000000\n",
      "Iter:   20 | Cost: 0.6514383 | Accuracy: 0.8000000\n",
      "Iter:   21 | Cost: 0.6419991 | Accuracy: 0.8000000\n",
      "Iter:   22 | Cost: 0.6321860 | Accuracy: 0.8000000\n",
      "Iter:   23 | Cost: 0.6227320 | Accuracy: 0.8000000\n",
      "Iter:   24 | Cost: 0.6147594 | Accuracy: 0.8000000\n",
      "Iter:   25 | Cost: 0.6061122 | Accuracy: 0.8000000\n",
      "Iter:   26 | Cost: 0.5985339 | Accuracy: 0.8000000\n",
      "Iter:   27 | Cost: 0.5909306 | Accuracy: 0.8000000\n",
      "Iter:   28 | Cost: 0.5834923 | Accuracy: 0.8000000\n",
      "Iter:   29 | Cost: 0.5762468 | Accuracy: 0.8000000\n",
      "Iter:   30 | Cost: 0.5685562 | Accuracy: 0.8000000\n",
      "Iter:   31 | Cost: 0.5625722 | Accuracy: 0.8000000\n",
      "Iter:   32 | Cost: 0.5569207 | Accuracy: 0.8000000\n",
      "Iter:   33 | Cost: 0.5523550 | Accuracy: 0.8000000\n",
      "Iter:   34 | Cost: 0.5491213 | Accuracy: 0.8000000\n",
      "Iter:   35 | Cost: 0.5473132 | Accuracy: 0.8000000\n",
      "Iter:   36 | Cost: 0.5453203 | Accuracy: 0.8000000\n",
      "Iter:   37 | Cost: 0.5439742 | Accuracy: 0.8000000\n",
      "Iter:   38 | Cost: 0.5424476 | Accuracy: 0.8000000\n",
      "Iter:   39 | Cost: 0.5410402 | Accuracy: 0.8000000\n",
      "Iter:   40 | Cost: 0.5400643 | Accuracy: 0.8000000\n",
      "Iter:   41 | Cost: 0.5397055 | Accuracy: 0.8000000\n",
      "Iter:   42 | Cost: 0.5395691 | Accuracy: 0.8000000\n",
      "Iter:   43 | Cost: 0.5375167 | Accuracy: 0.8000000\n",
      "Iter:   44 | Cost: 0.5342254 | Accuracy: 0.8000000\n",
      "Iter:   45 | Cost: 0.5303823 | Accuracy: 0.8000000\n",
      "Iter:   46 | Cost: 0.5269085 | Accuracy: 0.8000000\n",
      "Iter:   47 | Cost: 0.5243275 | Accuracy: 0.8000000\n",
      "Iter:   48 | Cost: 0.5224857 | Accuracy: 0.8000000\n",
      "Iter:   49 | Cost: 0.5210583 | Accuracy: 0.8000000\n",
      "Iter:   50 | Cost: 0.5199749 | Accuracy: 0.8000000\n",
      "Iter:   51 | Cost: 0.5192274 | Accuracy: 0.8000000\n",
      "Iter:   52 | Cost: 0.5190453 | Accuracy: 0.8000000\n",
      "Iter:   53 | Cost: 0.5180268 | Accuracy: 0.8000000\n",
      "Iter:   54 | Cost: 0.5166623 | Accuracy: 0.8000000\n",
      "Iter:   55 | Cost: 0.5150665 | Accuracy: 0.8000000\n",
      "Iter:   56 | Cost: 0.5142165 | Accuracy: 0.8000000\n",
      "Iter:   57 | Cost: 0.5124231 | Accuracy: 0.8000000\n",
      "Iter:   58 | Cost: 0.5097880 | Accuracy: 0.8000000\n",
      "Iter:   59 | Cost: 0.5066661 | Accuracy: 0.8000000\n",
      "Iter:   60 | Cost: 0.5039934 | Accuracy: 0.8000000\n",
      "Iter:   61 | Cost: 0.5019501 | Accuracy: 0.8000000\n",
      "Iter:   62 | Cost: 0.4995621 | Accuracy: 0.8000000\n",
      "Iter:   63 | Cost: 0.4963738 | Accuracy: 0.8000000\n",
      "Iter:   64 | Cost: 0.4936165 | Accuracy: 0.8000000\n",
      "Iter:   65 | Cost: 0.4906791 | Accuracy: 0.8000000\n",
      "Iter:   66 | Cost: 0.4877146 | Accuracy: 0.8000000\n",
      "Iter:   67 | Cost: 0.4840199 | Accuracy: 0.8000000\n",
      "Iter:   68 | Cost: 0.4808775 | Accuracy: 0.8000000\n",
      "Iter:   69 | Cost: 0.4781283 | Accuracy: 0.8000000\n",
      "Iter:   70 | Cost: 0.4749022 | Accuracy: 0.8000000\n",
      "Iter:   71 | Cost: 0.4711073 | Accuracy: 0.8000000\n",
      "Iter:   72 | Cost: 0.4672987 | Accuracy: 0.8000000\n",
      "Iter:   73 | Cost: 0.4631724 | Accuracy: 0.8000000\n",
      "Iter:   74 | Cost: 0.4595885 | Accuracy: 0.8000000\n",
      "Iter:   75 | Cost: 0.4560226 | Accuracy: 0.8000000\n",
      "Iter:   76 | Cost: 0.4524937 | Accuracy: 0.8000000\n",
      "Iter:   77 | Cost: 0.4486777 | Accuracy: 0.8000000\n",
      "Iter:   78 | Cost: 0.4448742 | Accuracy: 0.8000000\n",
      "Iter:   79 | Cost: 0.4410773 | Accuracy: 0.8000000\n",
      "Iter:   80 | Cost: 0.4376702 | Accuracy: 0.8000000\n",
      "Iter:   81 | Cost: 0.4339675 | Accuracy: 0.8000000\n",
      "Iter:   82 | Cost: 0.4306348 | Accuracy: 0.8000000\n",
      "Iter:   83 | Cost: 0.4269245 | Accuracy: 0.8000000\n",
      "Iter:   84 | Cost: 0.4235404 | Accuracy: 0.8000000\n",
      "Iter:   85 | Cost: 0.4204355 | Accuracy: 0.8000000\n",
      "Iter:   86 | Cost: 0.4177035 | Accuracy: 0.8000000\n",
      "Iter:   87 | Cost: 0.4143099 | Accuracy: 0.8000000\n",
      "Iter:   88 | Cost: 0.4109365 | Accuracy: 0.8000000\n",
      "Iter:   89 | Cost: 0.4070258 | Accuracy: 0.8000000\n",
      "Iter:   90 | Cost: 0.4029640 | Accuracy: 0.8000000\n",
      "Iter:   91 | Cost: 0.3990883 | Accuracy: 0.8000000\n",
      "Iter:   92 | Cost: 0.3953722 | Accuracy: 0.8000000\n",
      "Iter:   93 | Cost: 0.3918156 | Accuracy: 0.8000000\n",
      "Iter:   94 | Cost: 0.3883037 | Accuracy: 0.8000000\n",
      "Iter:   95 | Cost: 0.3849533 | Accuracy: 0.8000000\n",
      "Iter:   96 | Cost: 0.3815930 | Accuracy: 0.8000000\n",
      "Iter:   97 | Cost: 0.3779561 | Accuracy: 0.8000000\n",
      "Iter:   98 | Cost: 0.3743858 | Accuracy: 0.8000000\n",
      "Iter:   99 | Cost: 0.3708657 | Accuracy: 1.0000000\n",
      "Iter:  100 | Cost: 0.3673762 | Accuracy: 1.0000000\n"
     ]
    }
   ],
   "source": [
    "#opt = NesterovMomentumOptimizer(0.5)\n",
    "opt = qml.AdamOptimizer()\n",
    "batch_size = 5\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "for it in range(10):\n",
    "\n",
    "    # Update the weights by one optimizer step, using only a limited batch of data\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "    weights, bias = opt.step(cost, weights, bias, X=X_batch, Y=Y_batch)\n",
    "\n",
    "    # Compute accuracy\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "\n",
    "    current_cost = cost(weights, bias, X, Y)\n",
    "    acc = accuracy(Y, predictions)\n",
    "\n",
    "    print(f\"Iter: {it+1:4d} | Cost: {current_cost:0.7f} | Accuracy: {acc:0.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6dca2af1-99e5-4333-8476-ffac6aec5b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"AI_2qubits_training_data.txt\", dtype=int)\n",
    "X = np.array(data[:, :-1])\n",
    "Y = np.array(data[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ec84bdc2-c6ab-4228-b26e-3900b52fb7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_to_bits(binary_list):\n",
    "    return [[[int(i) for i in str(bit)] for bit in binary_string][0] for binary_string in binary_list]\n",
    "X = np.array(binary_to_bits(np.loadtxt(\"AI_2qubits_training_data.txt\", dtype = str)[:,:-1]))\n",
    "Y = np.loadtxt(\"AI_2qubits_training_data.txt\", dtype = str)[:,-1].astype(int)\n",
    "Y-=1\n",
    "def one_hot(y, num_classes):\n",
    "    return np.eye(num_classes)[y]\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_data_one_hot = one_hot(Y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5538cca9-26e2-438c-9fc7-70c9365d2b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "941ca844-0559-41cc-99d5-273bddbcdc5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "maximum supported dimension for an ndarray is 32, found 100",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m X_batch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X)[batch_index]\n\u001b[0;32m     16\u001b[0m Y_batch \u001b[38;5;241m=\u001b[39m y_data_one_hot[:,j][batch_index]\n\u001b[1;32m---> 17\u001b[0m weights, bias \u001b[38;5;241m=\u001b[39m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Compute accuracy\u001b[39;00m\n\u001b[0;32m     20\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39msign(variational_classifier(weights, bias, x)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X]\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pennylane\\optimize\\gradient_descent.py:93\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.step\u001b[1;34m(self, objective_fn, grad_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, objective_fn, \u001b[38;5;241m*\u001b[39margs, grad_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update trainable arguments with one step of the optimizer.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m        If single arg is provided, list [array] is replaced by array.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m     g, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     new_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_grad(g, args)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# unwrap from list if one argument, cleaner return\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pennylane\\optimize\\gradient_descent.py:122\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.compute_grad\u001b[1;34m(objective_fn, args, kwargs, grad_fn)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Compute gradient of the objective function at the given point and return it along with\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03mthe objective function forward pass (if available).\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03m    will not be evaluted and instead ``None`` will be returned.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    121\u001b[0m g \u001b[38;5;241m=\u001b[39m get_gradient(objective_fn) \u001b[38;5;28;01mif\u001b[39;00m grad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m grad_fn\n\u001b[1;32m--> 122\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(g, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    125\u001b[0m num_trainable_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pennylane\\_grad.py:165\u001b[0m, in \u001b[0;36mgrad.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n\u001b[1;32m--> 165\u001b[0m grad_value, ans \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward \u001b[38;5;241m=\u001b[39m ans\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_value\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\autograd\\wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(args[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnum)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munary_operator\u001b[49m\u001b[43m(\u001b[49m\u001b[43munary_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pennylane\\_grad.py:183\u001b[0m, in \u001b[0;36mgrad._grad_with_forward\u001b[1;34m(fun, x)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;129m@unary_to_nary\u001b[39m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_grad_with_forward\u001b[39m(fun, x):\n\u001b[0;32m    180\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function is a replica of ``autograd.grad``, with the only\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;124;03m    difference being that it returns both the gradient *and* the forward pass\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m    value.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m     vjp, ans \u001b[38;5;241m=\u001b[39m \u001b[43m_make_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=redefined-outer-name\u001b[39;00m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m vspace(ans)\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    187\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrad only applies to real scalar-output functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry jacobian, elementwise_grad or holomorphic_grad.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m         )\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\autograd\\core.py:10\u001b[0m, in \u001b[0;36mmake_vjp\u001b[1;34m(fun, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_vjp\u001b[39m(fun, x):\n\u001b[0;32m      9\u001b[0m     start_node \u001b[38;5;241m=\u001b[39m VJPNode\u001b[38;5;241m.\u001b[39mnew_root()\n\u001b[1;32m---> 10\u001b[0m     end_value, end_node \u001b[38;5;241m=\u001b[39m  \u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end_node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(g): \u001b[38;5;28;01mreturn\u001b[39;00m vspace(x)\u001b[38;5;241m.\u001b[39mzeros()\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\autograd\\tracer.py:10\u001b[0m, in \u001b[0;36mtrace\u001b[1;34m(start_node, fun, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace_stack\u001b[38;5;241m.\u001b[39mnew_trace() \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[0;32m      9\u001b[0m     start_box \u001b[38;5;241m=\u001b[39m new_box(x, t, start_node)\n\u001b[1;32m---> 10\u001b[0m     end_box \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_box\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isbox(end_box) \u001b[38;5;129;01mand\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_trace \u001b[38;5;241m==\u001b[39m start_box\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_value, end_box\u001b[38;5;241m.\u001b[39m_node\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\autograd\\wrap_util.py:15\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f.<locals>.unary_f\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     subargs \u001b[38;5;241m=\u001b[39m subvals(args, \u001b[38;5;28mzip\u001b[39m(argnum, x))\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msubargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[117], line 14\u001b[0m, in \u001b[0;36mcost\u001b[1;34m(weights, bias, X, Y)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcost\u001b[39m(weights, bias, X, Y):\n\u001b[1;32m---> 14\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mvariational_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m square_loss(Y, predictions)\n",
      "Cell \u001b[1;32mIn[117], line 14\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcost\u001b[39m(weights, bias, X, Y):\n\u001b[1;32m---> 14\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m [\u001b[43mvariational_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X]\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m square_loss(Y, predictions)\n",
      "Cell \u001b[1;32mIn[117], line 2\u001b[0m, in \u001b[0;36mvariational_classifier\u001b[1;34m(weights, bias, x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvariational_classifier\u001b[39m(weights, bias, x):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcircuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m bias\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pennylane\\workflow\\qnode.py:1048\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         full_transform_program\u001b[38;5;241m.\u001b[39m_set_all_argnums(\n\u001b[0;32m   1044\u001b[0m             \u001b[38;5;28mself\u001b[39m, args, kwargs, argnums\n\u001b[0;32m   1045\u001b[0m         )  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;66;03m# pylint: disable=unexpected-keyword-arg\u001b[39;00m\n\u001b[1;32m-> 1048\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_program\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_transform_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverride_shots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_shots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1060\u001b[0m res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pennylane\\workflow\\execution.py:684\u001b[0m, in \u001b[0;36mexecute\u001b[1;34m(tapes, device, gradient_fn, interface, transform_program, config, grad_on_execution, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform, device_vjp)\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;66;03m# Exiting early if we do not need to deal with an interface boundary\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_interface_boundary_required:\n\u001b[1;32m--> 684\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43minner_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m post_processing(results)\n\u001b[0;32m    687\u001b[0m _grad_on_execution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pennylane\\workflow\\execution.py:283\u001b[0m, in \u001b[0;36m_make_inner_execute.<locals>.inner_execute\u001b[1;34m(tapes, **_)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_only:\n\u001b[0;32m    282\u001b[0m     tapes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(qml\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mconvert_to_numpy_parameters(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tapes)\n\u001b[1;32m--> 283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcached_device_execution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pennylane\\workflow\\execution.py:361\u001b[0m, in \u001b[0;36mcache_execute.<locals>.wrapper\u001b[1;34m(tapes, **kwargs)\u001b[0m\n\u001b[0;32m    354\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(cache, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache):\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;66;03m# No caching. Simply execute the execution function\u001b[39;00m\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;66;03m# and return the results.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \n\u001b[0;32m    360\u001b[0m     \u001b[38;5;66;03m# must convert to list as new device interface returns tuples\u001b[39;00m\n\u001b[1;32m--> 361\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (res, []) \u001b[38;5;28;01mif\u001b[39;00m return_tuple \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m    364\u001b[0m execution_tapes \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pennylane\\devices\\modifiers\\simulator_tracking.py:30\u001b[0m, in \u001b[0;36m_track_execute.<locals>.execute\u001b[1;34m(self, circuits, execution_config)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(untracked_execute)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, circuits, execution_config\u001b[38;5;241m=\u001b[39mDefaultExecutionConfig):\n\u001b[1;32m---> 30\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43muntracked_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(circuits, QuantumScript):\n\u001b[0;32m     32\u001b[0m         batch \u001b[38;5;241m=\u001b[39m (circuits,)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pennylane\\devices\\modifiers\\single_tape_support.py:32\u001b[0m, in \u001b[0;36m_make_execute.<locals>.execute\u001b[1;34m(self, circuits, execution_config)\u001b[0m\n\u001b[0;32m     30\u001b[0m     is_single_circuit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     circuits \u001b[38;5;241m=\u001b[39m (circuits,)\n\u001b[1;32m---> 32\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m is_single_circuit \u001b[38;5;28;01melse\u001b[39;00m results\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pennylane\\devices\\default_qubit.py:553\u001b[0m, in \u001b[0;36mDefaultQubit.execute\u001b[1;34m(self, circuits, execution_config)\u001b[0m\n\u001b[0;32m    547\u001b[0m interface \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    548\u001b[0m     execution_config\u001b[38;5;241m.\u001b[39minterface\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m execution_config\u001b[38;5;241m.\u001b[39mgradient_method \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackprop\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    551\u001b[0m )\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_workers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m    554\u001b[0m         simulate(\n\u001b[0;32m    555\u001b[0m             c,\n\u001b[0;32m    556\u001b[0m             rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng,\n\u001b[0;32m    557\u001b[0m             prng_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prng_key,\n\u001b[0;32m    558\u001b[0m             debugger\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_debugger,\n\u001b[0;32m    559\u001b[0m             interface\u001b[38;5;241m=\u001b[39minterface,\n\u001b[0;32m    560\u001b[0m             state_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_cache,\n\u001b[0;32m    561\u001b[0m         )\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m circuits\n\u001b[0;32m    563\u001b[0m     )\n\u001b[0;32m    565\u001b[0m vanilla_circuits \u001b[38;5;241m=\u001b[39m [convert_to_numpy_parameters(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m circuits]\n\u001b[0;32m    566\u001b[0m seeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng\u001b[38;5;241m.\u001b[39mintegers(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m31\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(vanilla_circuits))\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pennylane\\devices\\default_qubit.py:554\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    547\u001b[0m interface \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    548\u001b[0m     execution_config\u001b[38;5;241m.\u001b[39minterface\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m execution_config\u001b[38;5;241m.\u001b[39mgradient_method \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackprop\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    551\u001b[0m )\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_workers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m--> 554\u001b[0m         \u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m            \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprng_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prng_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdebugger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_debugger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[43m            \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m circuits\n\u001b[0;32m    563\u001b[0m     )\n\u001b[0;32m    565\u001b[0m vanilla_circuits \u001b[38;5;241m=\u001b[39m [convert_to_numpy_parameters(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m circuits]\n\u001b[0;32m    566\u001b[0m seeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng\u001b[38;5;241m.\u001b[39mintegers(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m31\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(vanilla_circuits))\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pennylane\\devices\\qubit\\simulate.py:260\u001b[0m, in \u001b[0;36msimulate\u001b[1;34m(circuit, rng, prng_key, debugger, interface, state_cache)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m circuit\u001b[38;5;241m.\u001b[39mshots \u001b[38;5;129;01mand\u001b[39;00m has_mid_circuit_measurements(circuit):\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m simulate_native_mcm(\n\u001b[0;32m    258\u001b[0m         circuit, rng\u001b[38;5;241m=\u001b[39mrng, prng_key\u001b[38;5;241m=\u001b[39mprng_key, debugger\u001b[38;5;241m=\u001b[39mdebugger, interface\u001b[38;5;241m=\u001b[39minterface\n\u001b[0;32m    259\u001b[0m     )\n\u001b[1;32m--> 260\u001b[0m state, is_state_batched \u001b[38;5;241m=\u001b[39m \u001b[43mget_final_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebugger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebugger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    262\u001b[0m     state_cache[circuit\u001b[38;5;241m.\u001b[39mhash] \u001b[38;5;241m=\u001b[39m state\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pennylane\\devices\\qubit\\simulate.py:134\u001b[0m, in \u001b[0;36mget_final_state\u001b[1;34m(circuit, debugger, interface, mid_measurements)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(circuit) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(circuit[\u001b[38;5;241m0\u001b[39m], qml\u001b[38;5;241m.\u001b[39moperation\u001b[38;5;241m.\u001b[39mStatePrepBase):\n\u001b[0;32m    132\u001b[0m     prep \u001b[38;5;241m=\u001b[39m circuit[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 134\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_initial_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop_wires\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlike\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mINTERFACE_TO_LIKE\u001b[49m\u001b[43m[\u001b[49m\u001b[43minterface\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# initial state is batched only if the state preparation (if it exists) is batched\u001b[39;00m\n\u001b[0;32m    137\u001b[0m is_state_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(prep \u001b[38;5;129;01mand\u001b[39;00m prep\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pennylane\\devices\\qubit\\initialize_state.py:45\u001b[0m, in \u001b[0;36mcreate_initial_state\u001b[1;34m(wires, prep_operation, like)\u001b[0m\n\u001b[0;32m     42\u001b[0m     state[(\u001b[38;5;241m0\u001b[39m,) \u001b[38;5;241m*\u001b[39m num_wires] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39masarray(state, like\u001b[38;5;241m=\u001b[39mlike)\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39masarray(\u001b[43mprep_operation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwire_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwires\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, like\u001b[38;5;241m=\u001b[39mlike)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pennylane\\ops\\qubit\\state_preparation.py:120\u001b[0m, in \u001b[0;36mBasisState.state_vector\u001b[1;34m(self, wire_order)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m base_wire_label, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwires, prep_vals):\n\u001b[0;32m    118\u001b[0m         indices[wire_order\u001b[38;5;241m.\u001b[39mindex(base_wire_label)] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m--> 120\u001b[0m ket \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m2\u001b[39m,) \u001b[38;5;241m*\u001b[39m num_wires)\n\u001b[0;32m    121\u001b[0m ket[\u001b[38;5;28mtuple\u001b[39m(indices)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m math\u001b[38;5;241m.\u001b[39mconvert_like(ket, prep_vals)\n",
      "\u001b[1;31mValueError\u001b[0m: maximum supported dimension for an ndarray is 32, found 100"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "num_qubits = 100\n",
    "num_layers = 2\n",
    "weights_init = 0.01 * np.random.randn(3, num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "opt = qml.AdamOptimizer()\n",
    "batch_size = 5\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "for it in range(10):\n",
    "    for j in range(3):\n",
    "        # Update the weights by one optimizer step, using only a limited batch of data\n",
    "        batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "        X_batch = np.array(X)[batch_index]\n",
    "        Y_batch = y_data_one_hot[:,j][batch_index]\n",
    "        weights, bias = opt.step(cost, weights[j], bias, X=X_batch, Y=Y_batch)\n",
    "    \n",
    "        # Compute accuracy\n",
    "        predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "    \n",
    "        current_cost = cost(weights, bias, X, Y)\n",
    "        acc = accuracy(Y, predictions)\n",
    "    \n",
    "        print(f\"Iter: {it+1:4d} | Cost: {current_cost:0.7f} | Accuracy: {acc:0.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d58a319-2322-4f43-b016-7362a2e2c3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c237c7-4bb6-41d1-9afa-52cc78ce418d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91ddffc-4133-447f-a8af-bd9874f2d6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0833025b-33f0-4906-ac39-31c19f736cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
